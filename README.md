# ğŸ–ï¸ Lieutenant â€” Voice Assistant

A Jarvis-style voice assistant system with Greek language support, offline wake word detection, streaming speech-to-text, intelligent agent responses, and a premium web UI with majestic waveform visualizations.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Voice Daemon  â”‚
â”‚  (React+TS)  â”‚   mic.level, stt,  â”‚   (Python)    â”‚
â”‚  port 5173   â”‚   agent, tts, etc  â”‚   port 8765   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚ HTTP SSE
                                            â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Agent Gateway  â”‚
                                    â”‚ (Python FastAPI)â”‚
                                    â”‚   port 8800    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Packages

| Package | Tech | Purpose |
|---|---|---|
| `packages/voice-daemon` | Python 3.11+ | Mic capture, wake word, STT, TTS, WebSocket hub |
| `packages/agent-gateway` | Python FastAPI | OpenAI-compatible API, tool execution, agent logic |
| `packages/web-ui` | Vite + React + TS | Waveform visualization, transcript, controls |

### Data Flow

1. **Voice Daemon** captures microphone audio continuously
2. **Wake Detection** (Vosk Greek) triggers on "Î¥Ï€Î¿Î»Î¿Ï‡Î±Î³Î­"
3. **Streaming STT** (faster-whisper) transcribes speech â†’ partial/final results to UI
4. **Agent Gateway** receives text, streams response tokens back via SSE
5. **TTS** speaks response (sentence-chunked, starts within ~1s)
6. **Waveform** reacts to mic RMS (listening) or speaker RMS (speaking)

---

## Quick Start

### Prerequisites

- **macOS** (primary target) or Linux
- **Python 3.11+**
- **Node.js 18+** and npm
- **portaudio** (for microphone access)

### 1. Install System Dependencies

```bash
# macOS
brew install portaudio python@3.11 node

# Linux (Debian/Ubuntu)
sudo apt-get install portaudio19-dev python3.11 python3.11-venv nodejs npm espeak
```

### 2. Clone & Setup

```bash
git clone <repo-url> lieutenant
cd lieutenant
cp .env.example .env   # Edit as needed
make install
```

### 3. Download Vosk Greek Model

The wake word detector requires a Vosk Greek model:

```bash
cd packages/voice-daemon/models
wget https://alphacephei.com/vosk/models/vosk-model-small-el-gr-0.15.zip
unzip vosk-model-small-el-gr-0.15.zip
cd ../../..
```

### 4. Run

```bash
make dev
```

Open **http://127.0.0.1:5173** in your browser.

---

## Usage

### Voice Interaction

1. Say **"Î¥Ï€Î¿Î»Î¿Ï‡Î±Î³Î­"** to activate (or click the ğŸ¤ button)
2. Speak your request in Greek
3. Watch the live transcript appear above the waveform
4. The assistant's response streams below the waveform
5. The assistant speaks the response aloud
6. The waveform reacts to your voice (green, listening) and the assistant's voice (purple, speaking)

### Controls

| Control | Action |
|---|---|
| ğŸ¤ Button | Simulate wake word (manual trigger) |
| â–  Stop | Kill switch â€” stops everything immediately |
| âš™ Settings | View configuration and backend status |

### Barge-in

Speak while the assistant is talking to interrupt (barge-in). TTS stops and the system resumes listening.

---

## Configuration

Edit `.env` at the repo root:

```env
# Ports
VOICE_DAEMON_PORT=8765
GATEWAY_PORT=8800
UI_PORT=5173

# Safety: require confirmation for destructive tool actions
SAFE_MODE=false

# Optional: OpenAI API key for LLM-powered agent reasoning
# OPENAI_API_KEY=sk-...

# Optional: Azure Speech for cloud STT/TTS
# AZURE_SPEECH_KEY=
# AZURE_SPEECH_REGION=westeurope

# STT/TTS backends
STT_BACKEND=local       # local | azure
TTS_BACKEND=local       # local | say | azure
STT_MODEL_SIZE=base     # tiny | base | small | medium | large-v3
```

### Backend Modes

| Feature | No API Key (Default) | With OpenAI Key | With Azure Key |
|---|---|---|---|
| Agent | Local rules + tools | GPT-4o-mini reasoning | GPT-4o-mini reasoning |
| STT | faster-whisper (local) | faster-whisper (local) | Azure Speech |
| TTS | macOS `say` / espeak | macOS `say` / espeak | Azure Neural TTS |

---

## Agent Gateway â€” OpenAI-Compatible API

The gateway exposes a standard OpenAI-compatible API:

```bash
# List models
curl http://127.0.0.1:8800/v1/models

# Chat (non-streaming)
curl http://127.0.0.1:8800/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"local-agent","messages":[{"role":"user","content":"Î“ÎµÎ¹Î± ÏƒÎ¿Ï…!"}]}'

# Chat (streaming SSE)
curl http://127.0.0.1:8800/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"local-agent","messages":[{"role":"user","content":"Ï„ÏÎ­Î¾Îµ ls -la"}],"stream":true}'
```

### Built-in Tools

| Tool | Trigger Phrases | Description |
|---|---|---|
| `shell` | Ï„ÏÎ­Î¾Îµ, ÎµÎºÏ„Î­Î»ÎµÏƒÎµ, run | Execute shell commands |
| `fs_read` | Î´Î¹Î¬Î²Î±ÏƒÎµ, read, Î´ÎµÎ¯Î¾Îµ | Read files |
| `fs_write` | Î³ÏÎ¬ÏˆÎµ, write, Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎµ | Write files |
| `http_get` | ÎºÎ±Ï„Î­Î²Î±ÏƒÎµ, Ï†Î­ÏÎµ, fetch | HTTP GET requests |

All tool calls are logged to `logs/audit.jsonl`.

---

## Voice Daemon â€” Control API

```bash
# Simulate wake word
curl -X POST http://127.0.0.1:8765/control/wake

# Kill switch (stop everything)
curl -X POST http://127.0.0.1:8765/control/stop

# Push-to-talk start/stop
curl -X POST http://127.0.0.1:8765/control/push_to_talk/start
curl -X POST http://127.0.0.1:8765/control/push_to_talk/stop

# Status
curl http://127.0.0.1:8765/status
```

### WebSocket Messages

Connect to `ws://127.0.0.1:8765/ws` to receive real-time events:

```json
{"type": "state", "value": "IDLE"}
{"type": "mic.level", "rms": 0.12}
{"type": "stt.partial", "text": "Î¸Î­Î»Ï‰ Î½Î± ..."}
{"type": "stt.final", "text": "Î¸Î­Î»Ï‰ Î½Î± Î¼Î¿Ï… Ï€ÎµÎ¹Ï‚ Ï„Î¿Î½ ÎºÎ±Î¹ÏÏŒ"}
{"type": "agent.chunk", "text": "Î’ÎµÎ²Î±Î¯Ï‰Ï‚, "}
{"type": "agent.done"}
{"type": "tts.level", "rms": 0.08}
{"type": "error", "message": "..."}
```

---

## State Machine

```
IDLE â”€â”€(wake)â”€â”€â–º LISTENING â”€â”€(final transcript)â”€â”€â–º THINKING â”€â”€(first agent chunk)â”€â”€â–º SPEAKING â”€â”€(TTS done)â”€â”€â–º IDLE
  â–²                                                                                      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (kill switch) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â–²           â”‚
                                                    â””â”€â”€(barge-in)â”€â”€â”˜
```

---

## Replacing Agent Gateway with OpenClaw

The Agent Gateway is designed as a **drop-in replacement target**. To swap it with OpenClaw:

1. **OpenClaw must expose** the same endpoints:
   - `POST /v1/chat/completions` (with `stream=true` SSE support)
   - `GET /v1/models`

2. **Update `.env`**:
   ```env
   GATEWAY_PORT=<openclaw-port>
   ```

3. **No changes needed** in voice-daemon or web-ui â€” they communicate via the standard OpenAI API format.

The voice-daemon's `agent_client.py` uses standard HTTP SSE streaming against the `/v1/chat/completions` endpoint, making it backend-agnostic.

---

## Troubleshooting

| Issue | Solution |
|---|---|
| No microphone access | Check `System Preferences > Privacy > Microphone` on macOS |
| `portaudio` not found | `brew install portaudio` (macOS) or `apt-get install portaudio19-dev` (Linux) |
| Vosk model missing | Download from https://alphacephei.com/vosk/models â€” extract to `packages/voice-daemon/models/` |
| No Greek TTS voice | Install Greek voice in macOS `System Preferences > Accessibility > Speech`. On Linux: `apt-get install espeak` |
| faster-whisper slow | Use `STT_MODEL_SIZE=tiny` for faster (lower quality) transcription |
| WebSocket not connecting | Ensure voice-daemon is running on port 8765 |
| Agent not responding | Ensure agent-gateway is running on port 8800 |

---

## Project Structure

```
lieutenant/
â”œâ”€â”€ .env.example              # Configuration template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Makefile                  # dev, start, install, clean
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ agent-gateway/        # OpenAI-compatible agent API
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â”œâ”€â”€ main.py       # FastAPI app
â”‚   â”‚       â”œâ”€â”€ routes/
â”‚   â”‚       â”‚   â”œâ”€â”€ chat.py   # /v1/chat/completions
â”‚   â”‚       â”‚   â””â”€â”€ models.py # /v1/models
â”‚   â”‚       â””â”€â”€ agent/
â”‚   â”‚           â”œâ”€â”€ core.py   # Agent reasoning + tool dispatch
â”‚   â”‚           â”œâ”€â”€ tools.py  # fs_read, fs_write, shell, http_get
â”‚   â”‚           â””â”€â”€ audit.py  # Tool call audit logging
â”‚   â”‚
â”‚   â”œâ”€â”€ voice-daemon/         # Voice processing daemon
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ models/           # Vosk models (gitignored)
â”‚   â”‚   â””â”€â”€ lieutenant_daemon/
â”‚   â”‚       â”œâ”€â”€ __init__.py   # Entry point
â”‚   â”‚       â”œâ”€â”€ __main__.py
â”‚   â”‚       â”œâ”€â”€ server.py     # FastAPI + orchestration
â”‚   â”‚       â”œâ”€â”€ state.py      # State machine
â”‚   â”‚       â”œâ”€â”€ ws_hub.py     # WebSocket broadcasting
â”‚   â”‚       â”œâ”€â”€ audio_capture.py  # Mic input
â”‚   â”‚       â”œâ”€â”€ wake.py       # Wake word detection (Vosk)
â”‚   â”‚       â”œâ”€â”€ stt.py        # Speech-to-text (faster-whisper)
â”‚   â”‚       â”œâ”€â”€ tts.py        # Text-to-speech (say/piper/azure)
â”‚   â”‚       â””â”€â”€ agent_client.py   # Agent gateway HTTP client
â”‚   â”‚
â”‚   â””â”€â”€ web-ui/               # React web interface
â”‚       â”œâ”€â”€ package.json
â”‚       â”œâ”€â”€ tsconfig.json
â”‚       â”œâ”€â”€ vite.config.ts
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ main.tsx
â”‚           â”œâ”€â”€ App.tsx
â”‚           â”œâ”€â”€ index.css
â”‚           â”œâ”€â”€ types.ts
â”‚           â”œâ”€â”€ hooks/
â”‚           â”‚   â””â”€â”€ useDaemon.ts  # WebSocket connection hook
â”‚           â””â”€â”€ components/
â”‚               â”œâ”€â”€ Waveform.tsx       # Canvas waveform visualization
â”‚               â”œâ”€â”€ StateIndicator.tsx # State display
â”‚               â”œâ”€â”€ Transcript.tsx     # STT transcript
â”‚               â”œâ”€â”€ AgentResponse.tsx  # Streaming agent text
â”‚               â”œâ”€â”€ Controls.tsx       # Wake + Kill buttons
â”‚               â””â”€â”€ Settings.tsx       # Settings drawer
â”‚
â””â”€â”€ logs/                     # Runtime logs (gitignored)
    â””â”€â”€ audit.jsonl           # Tool call audit trail
```

---

## Key Design Decisions

1. **Agent Gateway in Python (FastAPI)** â€” Chosen over Node.js for consistency with the voice-daemon (both Python), shared tooling, and because the optional OpenAI Python SDK is first-class. FastAPI provides native async/SSE streaming.

2. **Vosk for wake word** â€” True custom KWS for "Î¥Ï€Î¿Î»Î¿Ï‡Î±Î³Î­" would require training a model (days of work). Instead, we run lightweight continuous Vosk recognition on Greek audio and trigger when the transcript contains the wake phrase. Low CPU with the small Greek model (~50MB).

3. **faster-whisper for STT** â€” Best quality/speed tradeoff for offline Greek transcription. Uses CTranslate2 (int8 quantization) for CPU efficiency. Partial results emitted every ~1s of audio.

4. **Sentence-chunked TTS** â€” Instead of waiting for the full agent response, we buffer until sentence boundaries and start TTS immediately. This gives perceived latency of ~1s from first agent tokens.

5. **Echo suppression** â€” During TTS playback, wake detection is disabled to prevent the speaker output from re-triggering the wake word. Re-enabled after TTS completes or on kill switch.

6. **All services on localhost** â€” Security by default. No external network exposure.

---

## License

See [LICENSE](LICENSE).
