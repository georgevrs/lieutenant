# ğŸ–ï¸ Lieutenant â€” Voice Assistant

A Jarvis-style, bilingual (Greek / English) voice assistant with offline wake word detection, real-time streaming STT, intelligent LLM-powered agent responses, edge-based neural TTS, barge-in interruption, conversation mode, and a premium web UI with waveform visualizations.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Voice Daemon  â”‚
â”‚  (React+TS)  â”‚  state, stt, agent, â”‚   (Python)    â”‚
â”‚  port 5173   â”‚  tts, settings, i18nâ”‚   port 8765   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ HTTP SSE
                                             â–¼
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚ Agent Gateway  â”‚
                                     â”‚ (Python FastAPI)â”‚
                                     â”‚   port 8800    â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â–¼              â–¼              â–¼
                        OpenClaw CLI   Google Gemini   OpenAI GPT
                        (primary)      (fallback)      (fallback)
```

### Packages

| Package | Tech | Purpose |
|---|---|---|
| `packages/voice-daemon` | Python 3.11+ | Mic capture, wake word (Vosk), STT (faster-whisper), TTS (edge-tts), barge-in, settings |
| `packages/agent-gateway` | Python FastAPI | OpenAI-compatible API, OpenClaw/Gemini/GPT, tool execution, bilingual prompts |
| `packages/web-ui` | Vite + React + TS | Waveform, transcript, chat panel, controls, settings panel, i18n |

### Data Flow

1. **Voice Daemon** captures microphone audio continuously (16 kHz, mono)
2. **Wake Detection** (Vosk, grammar-constrained) triggers on "Î¥Ï€Î¿Î»Î¿Ï‡Î±Î³Î­" (Greek) or "Lieutenant" (English)
3. **Streaming STT** (faster-whisper medium, CTranslate2 int8) transcribes speech â†’ partial/final results to UI
4. **Agent Gateway** receives text, dispatches to OpenClaw CLI (primary) â†’ Gemini (fallback) â†’ local tools
5. **TTS** (edge-tts, Microsoft Neural voices) speaks response sentence-by-sentence (starts within ~1s)
6. **Waveform** reacts to mic RMS (listening/green) or speaker RMS (speaking/purple)
7. **Conversation mode** keeps listening after response â€” speak again without repeating the wake word

---

## Features

- **Bilingual**: Full Greek and English support â€” switch language live from the UI
- **Offline wake word**: Vosk-based, dual-model (Greek + English), grammar-constrained for reliability
- **Customizable wake words**: Change wake phrases and display name from the Settings panel (persisted to `.env`)
- **Streaming STT**: faster-whisper medium model with Silero VAD, auto-gain normalization
- **Neural TTS**: Microsoft edge-tts (male or female voices, Greek: `el-GR-NestorasNeural` / English: `en-US-GuyNeural`)
- **Barge-in**: Speak while the assistant is talking to interrupt â€” RMS-based energy detection
- **Conversation mode**: After a response, the system listens for follow-up questions (configurable timeout)
- **TTS echo suppression**: STT is deferred until TTS playback finishes + 0.5s guard to avoid hearing its own output
- **Markdown / emoji stripping**: Agent responses are cleaned before TTS for natural speech
- **Chat panel**: Plain-text conversation view with customizable assistant display name
- **LLM backends**: OpenClaw CLI (primary), Google Gemini (fallback), OpenAI GPT (fallback)
- **i18n**: Full Greek + English UI translations
- **Tool execution**: Shell commands, file I/O, HTTP requests â€” all audit-logged

---

## Quick Start

### Prerequisites

- **macOS** (primary target) or Linux
- **Python 3.11+**
- **Node.js 18+** and npm
- **portaudio** (for microphone access)

### 1. Install System Dependencies

```bash
# macOS
brew install portaudio python@3.11 node

# Linux (Debian/Ubuntu)
sudo apt-get install portaudio19-dev python3.11 python3.11-venv nodejs npm
```

### 2. Clone & Setup

```bash
git clone <repo-url> lieutenant
cd lieutenant
cp .env.example .env   # Edit as needed
make install
```

### 3. Download Vosk Models

Wake word detection requires Vosk models. Download and extract to `packages/voice-daemon/models/`:

```bash
cd packages/voice-daemon/models

# Greek model (required)
wget https://alphacephei.com/vosk/models/vosk-model-el-gr-0.7.zip
unzip vosk-model-el-gr-0.7.zip && rm vosk-model-el-gr-0.7.zip

# English model (optional, for English wake word)
wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
unzip vosk-model-small-en-us-0.15.zip && rm vosk-model-small-en-us-0.15.zip

cd ../../..
```

### 4. (Optional) Install OpenClaw

OpenClaw is the primary LLM backend. If installed, Lieutenant will use it automatically:

```bash
# Follow OpenClaw installation instructions at https://github.com/ANG13T/openclaw
# Ensure the `openclaw` CLI is in your PATH
```

If OpenClaw is not available, the gateway falls back to Google Gemini (requires `GOOGLE_API_KEY` in `.env`) or OpenAI GPT.

### 5. Run

```bash
make dev
```

Open **http://127.0.0.1:5173** in your browser.

---

## Usage

### Voice Interaction

1. Say **"Î¥Ï€Î¿Î»Î¿Ï‡Î±Î³Î­"** (Greek) or **"Lieutenant"** (English) to activate â€” or click the ğŸ¤ button
2. Speak your request
3. Watch the live transcript appear in the chat panel
4. The assistant streams its response and speaks it aloud
5. **Conversation mode**: After the response, speak again without repeating the wake word (times out after 5s of silence)
6. **Barge-in**: Speak while the assistant is talking to interrupt it

### Controls

| Control | Action |
|---|---|
| ğŸ¤ Button | Simulate wake word (manual trigger) |
| â–  Stop | Kill switch â€” stops everything immediately |
| ğŸŒ Language | Toggle between Greek and English |
| âš™ Settings | Wake words, display name, connection info |

### Settings Panel

From Settings (âš™) you can customize:
- **Greek wake word** â€” the phrase that activates the assistant in Greek (default: "Ï…Ï€Î¿Î»Î¿Ï‡Î±Î³Î­")
- **English wake word** â€” the phrase for English activation (default: "lieutenant")
- **Display name** â€” the assistant's name shown in the chat panel

Changes are auto-saved to the `.env` file and take effect immediately.

---

## Configuration

Edit `.env` at the repo root (copy from `.env.example`):

```env
# Ports
VOICE_DAEMON_PORT=8765
GATEWAY_PORT=8800
UI_PORT=5173

# Safety: require confirmation for destructive tool actions
SAFE_MODE=false

# Voice daemon settings
WAKE_PHRASE=Ï…Ï€Î¿Î»Î¿Ï‡Î±Î³Î­             # Greek wake phrase (also settable from UI)
WAKE_PHRASE_EN=lieutenant          # English wake phrase
DISPLAY_NAME=Lieutenant            # Chat display name
STT_BACKEND=local                  # local | azure
TTS_BACKEND=edge                   # edge | say | azure
STT_MODEL_SIZE=medium              # tiny | base | small | medium | large-v3
TTS_VOICE_GENDER=female            # female | male
LANGUAGE=el                        # el | en (startup language)

# Conversation mode
CONVERSE_MODE=true                 # true | false
CONVERSE_TIMEOUT=5.0               # seconds to wait for follow-up
MAX_HISTORY=30                     # max conversation turns in memory

# Barge-in tuning
BARGEIN_RMS_THRESHOLD=0.035        # mic energy to trigger interruption
BARGEIN_FRAMES_NEEDED=8            # consecutive high-energy frames (~512ms)
BARGEIN_COOLDOWN_S=1.5             # ignore barge-in for N s after TTS starts
BARGEIN_POST_TTS_GUARD_S=1.2       # guard after each TTS chunk ends

# TTS echo suppression
TTS_ECHO_GUARD_S=0.5               # suppress STT for N s after TTS ends

# LLM backends (agent-gateway)
OPENCLAW_TOKEN=                    # OpenClaw access token
OPENCLAW_WS_URL=ws://127.0.0.1:18789/ws
# GOOGLE_API_KEY=                  # Gemini fallback
# OPENAI_API_KEY=sk-...            # OpenAI fallback
HF_TOKEN=                          # HuggingFace (for Silero VAD download)
```

### LLM Backend Priority

| Priority | Backend | Requirement |
|---|---|---|
| 1 | **OpenClaw CLI** | `openclaw` in PATH |
| 2 | **Google Gemini** | `GOOGLE_API_KEY` set |
| 3 | **OpenAI GPT** | `OPENAI_API_KEY` set |
| 4 | **Local tool dispatch** | Always available (shell, fs, http) |

The active backend is shown in the UI's chat panel via a badge indicator.

### TTS Backends

| Backend | Config | Voice |
|---|---|---|
| **edge-tts** (default) | `TTS_BACKEND=edge` | Microsoft Neural â€” `el-GR-NestorasNeural` / `en-US-GuyNeural` (male) or `el-GR-AthinaNeural` / `en-US-JennyNeural` (female) |
| **macOS say** | `TTS_BACKEND=say` | System voice |
| **Azure Speech** | `TTS_BACKEND=azure` | Azure Neural TTS (requires key) |

---

## Agent Gateway â€” OpenAI-Compatible API

The gateway exposes a standard OpenAI-compatible API:

```bash
# List models
curl http://127.0.0.1:8800/v1/models

# Chat (non-streaming)
curl http://127.0.0.1:8800/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"local-agent","messages":[{"role":"user","content":"Î“ÎµÎ¹Î± ÏƒÎ¿Ï…!"}]}'

# Chat (streaming SSE)
curl http://127.0.0.1:8800/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"local-agent","messages":[{"role":"user","content":"Ï„ÏÎ­Î¾Îµ ls -la"}],"stream":true}'

# Switch language
curl -X POST http://127.0.0.1:8800/v1/language \
  -H "Content-Type: application/json" \
  -d '{"language":"en"}'
```

### Built-in Tools

| Tool | Trigger Phrases | Description |
|---|---|---|
| `shell` | Ï„ÏÎ­Î¾Îµ, ÎµÎºÏ„Î­Î»ÎµÏƒÎµ, run, execute | Execute shell commands |
| `fs_read` | Î´Î¹Î¬Î²Î±ÏƒÎµ, read, Î´ÎµÎ¯Î¾Îµ, show | Read files |
| `fs_write` | Î³ÏÎ¬ÏˆÎµ, write, Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎµ, save | Write files |
| `http_get` | ÎºÎ±Ï„Î­Î²Î±ÏƒÎµ, Ï†Î­ÏÎµ, fetch, get | HTTP GET requests |

All tool calls are logged to `logs/audit.jsonl`.

---

## Voice Daemon â€” Control API

```bash
# Simulate wake word
curl -X POST http://127.0.0.1:8765/control/wake

# Kill switch (stop everything)
curl -X POST http://127.0.0.1:8765/control/stop

# Push-to-talk
curl -X POST http://127.0.0.1:8765/control/push_to_talk/start
curl -X POST http://127.0.0.1:8765/control/push_to_talk/stop

# Get/set language
curl http://127.0.0.1:8765/control/language
curl -X POST http://127.0.0.1:8765/control/language \
  -H "Content-Type: application/json" -d '{"language":"en"}'

# Get/set settings (wake words + display name)
curl http://127.0.0.1:8765/control/settings
curl -X POST http://127.0.0.1:8765/control/settings \
  -H "Content-Type: application/json" \
  -d '{"wake_phrase_el":"Ï…Ï€Î¿Î»Î¿Ï‡Î±Î³Î­","wake_phrase_en":"lieutenant","display_name":"Lieutenant"}'

# Status
curl http://127.0.0.1:8765/status
```

### WebSocket Messages

Connect to `ws://127.0.0.1:8765/ws` to receive real-time events:

```json
{"type": "state",       "value": "IDLE"}
{"type": "mic.level",   "rms": 0.12}
{"type": "stt.partial", "text": "Î¸Î­Î»Ï‰ Î½Î± ..."}
{"type": "stt.final",   "text": "Î¸Î­Î»Ï‰ Î½Î± Î¼Î¿Ï… Ï€ÎµÎ¹Ï‚ Ï„Î¿Î½ ÎºÎ±Î¹ÏÏŒ"}
{"type": "agent.chunk", "text": "Î’ÎµÎ²Î±Î¯Ï‰Ï‚, "}
{"type": "agent.done",  "backend": "openclaw"}
{"type": "tts.level",   "rms": 0.08}
{"type": "language",    "value": "el"}
{"type": "settings",    "wake_phrase_el": "Ï…Ï€Î¿Î»Î¿Ï‡Î±Î³Î­", "wake_phrase_en": "lieutenant", "display_name": "Lieutenant"}
{"type": "error",       "message": "..."}
```

---

## State Machine

```
IDLE â”€â”€(wake)â”€â”€â–º LISTENING â”€â”€(final transcript)â”€â”€â–º THINKING â”€â”€(first chunk)â”€â”€â–º SPEAKING â”€â”€(TTS done)â”€â”€â–º IDLE
  â–²                                                                                     â”‚          â”‚
  â”‚                                                                                     â”‚    (converse
  â””â”€â”€â”€â”€ (kill switch) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    timeout)
                                        â–²              â”‚                                      â”‚
                                        â””â”€â”€(barge-in)â”€â”€â”˜              LISTENING â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                   (follow-up, no wake word needed)
```

### Key Transitions

- **Wake** â†’ IDLE to LISTENING (via wake word, button, or API)
- **Barge-in** â†’ SPEAKING to LISTENING (user speaks over TTS, TTS stops)
- **Conversation mode** â†’ SPEAKING to LISTENING (after TTS ends, waits for follow-up)
- **Kill switch** â†’ Any state to IDLE (stops STT, TTS, agent)

---

## Replacing Agent Gateway with OpenClaw

The Agent Gateway is designed as a **drop-in replacement target**. To swap it with OpenClaw:

1. **OpenClaw must expose** the same endpoints:
   - `POST /v1/chat/completions` (with `stream=true` SSE support)
   - `GET /v1/models`

2. **Update `.env`**:
   ```env
   GATEWAY_PORT=<openclaw-port>
   ```

3. **No changes needed** in voice-daemon or web-ui â€” they communicate via the standard OpenAI API format.

The voice-daemon's `agent_client.py` uses standard HTTP SSE streaming against the `/v1/chat/completions` endpoint, making it backend-agnostic.

---

## Troubleshooting

| Issue | Solution |
|---|---|
| No microphone access | Check `System Preferences > Privacy > Microphone` on macOS |
| `portaudio` not found | `brew install portaudio` (macOS) or `apt install portaudio19-dev` (Linux) |
| Vosk model missing | Download from https://alphacephei.com/vosk/models â€” extract to `packages/voice-daemon/models/` |
| English wake word not triggering | Ensure `vosk-model-small-en-us-0.15` is in `models/`. Switch to English via the UI language toggle. |
| faster-whisper slow on CPU | Use `STT_MODEL_SIZE=small` or `tiny` for faster (lower quality) transcription |
| TTS not speaking | Verify `TTS_BACKEND=edge` in `.env`. Check internet connection (edge-tts requires network). |
| Agent not responding | Ensure agent-gateway is running on port 8800. Check if OpenClaw/Gemini key is configured. |
| Echo / self-triggering | Increase `TTS_ECHO_GUARD_S` (default 0.5) or `BARGEIN_POST_TTS_GUARD_S` (default 1.2) |
| WebSocket not connecting | Ensure voice-daemon is running on port 8765 |

---

## Project Structure

```
lieutenant/
â”œâ”€â”€ .env.example              # Configuration template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Makefile                  # dev, start, install, clean
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ agent-gateway/        # OpenAI-compatible agent API
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â”œâ”€â”€ main.py       # FastAPI app
â”‚   â”‚       â”œâ”€â”€ routes/
â”‚   â”‚       â”‚   â”œâ”€â”€ chat.py   # /v1/chat/completions (SSE streaming)
â”‚   â”‚       â”‚   â”œâ”€â”€ models.py # /v1/models
â”‚   â”‚       â”‚   â””â”€â”€ language.py # /v1/language
â”‚   â”‚       â””â”€â”€ agent/
â”‚   â”‚           â”œâ”€â”€ core.py   # OpenClaw CLI + Gemini fallback + tool dispatch
â”‚   â”‚           â”œâ”€â”€ tools.py  # fs_read, fs_write, shell, http_get
â”‚   â”‚           â””â”€â”€ audit.py  # Tool call audit logging
â”‚   â”‚
â”‚   â”œâ”€â”€ voice-daemon/         # Voice processing daemon
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ models/           # Vosk models (gitignored)
â”‚   â”‚   â”‚   â”œâ”€â”€ vosk-model-el-gr-0.7/         # Greek wake word model
â”‚   â”‚   â”‚   â””â”€â”€ vosk-model-small-en-us-0.15/  # English wake word model
â”‚   â”‚   â””â”€â”€ lieutenant_daemon/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ __main__.py   # Entry point
â”‚   â”‚       â”œâ”€â”€ server.py     # FastAPI + orchestration + settings + state machine
â”‚   â”‚       â”œâ”€â”€ state.py      # State machine (IDLE/LISTENING/THINKING/SPEAKING)
â”‚   â”‚       â”œâ”€â”€ ws_hub.py     # WebSocket broadcasting
â”‚   â”‚       â”œâ”€â”€ audio_capture.py  # Mic input (portaudio, 16kHz mono)
â”‚   â”‚       â”œâ”€â”€ wake.py       # Wake word detection (Vosk, dual-model, grammar-based)
â”‚   â”‚       â”œâ”€â”€ stt.py        # Speech-to-text (faster-whisper + Silero VAD)
â”‚   â”‚       â”œâ”€â”€ tts.py        # Text-to-speech (edge-tts neural voices)
â”‚   â”‚       â””â”€â”€ agent_client.py   # Agent gateway HTTP SSE client
â”‚   â”‚
â”‚   â””â”€â”€ web-ui/               # React web interface
â”‚       â”œâ”€â”€ package.json
â”‚       â”œâ”€â”€ tsconfig.json
â”‚       â”œâ”€â”€ vite.config.ts
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ main.tsx
â”‚           â”œâ”€â”€ App.tsx       # Main layout + state wiring
â”‚           â”œâ”€â”€ index.css
â”‚           â”œâ”€â”€ types.ts      # Shared TypeScript types
â”‚           â”œâ”€â”€ i18n.ts       # Greek/English UI translations
â”‚           â”œâ”€â”€ hooks/
â”‚           â”‚   â””â”€â”€ useDaemon.ts  # WebSocket + settings state
â”‚           â””â”€â”€ components/
â”‚               â”œâ”€â”€ Waveform.tsx       # Canvas waveform visualization
â”‚               â”œâ”€â”€ StateIndicator.tsx # State display with i18n
â”‚               â”œâ”€â”€ Transcript.tsx     # Live STT transcript
â”‚               â”œâ”€â”€ AgentResponse.tsx  # Streaming agent text
â”‚               â”œâ”€â”€ ChatPanel.tsx      # Conversation view (plain text, display name)
â”‚               â”œâ”€â”€ Controls.tsx       # Wake + Kill + Language buttons
â”‚               â”œâ”€â”€ LogPanel.tsx       # Real-time daemon logs
â”‚               â””â”€â”€ Settings.tsx       # Editable wake words + display name
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download-vosk-model.sh  # Vosk model downloader
â”‚   â”œâ”€â”€ test_openclaw_ws.js     # OpenClaw WebSocket test
â”‚   â””â”€â”€ test_suite.py           # Integration test suite
â”‚
â””â”€â”€ logs/                     # Runtime logs (gitignored)
    â””â”€â”€ audit.jsonl           # Tool call audit trail
```

---

## Key Design Decisions

1. **Edge-TTS for speech synthesis** â€” Microsoft Neural TTS voices via the `edge-tts` package, providing high-quality Greek and English voices for free over the network. Sentence-chunked for low perceived latency (~1s from first agent tokens).

2. **faster-whisper medium for STT** â€” Best quality/speed tradeoff for offline bilingual transcription. Uses CTranslate2 (int8 quantization) for CPU efficiency. Combined with Silero VAD for utterance detection and auto-gain normalization.

3. **Vosk grammar-based wake word** â€” Instead of training a custom KWS model, we run lightweight Vosk recognition constrained to a grammar containing only the wake phrase. Dual-model support (Greek 50MB + English 40MB) with hot-reloading on language switch. Phonetic variant matching for robustness.

4. **OpenClaw â†’ Gemini fallback** â€” OpenClaw CLI is the primary LLM backend (runs locally). If unavailable, falls back to Google Gemini API, then OpenAI. Bilingual system prompts instruct the LLM to avoid markdown/emoji for clean TTS output.

5. **TTS echo suppression** â€” STT start is deferred until after acknowledgment TTS finishes + a 0.5s guard. During TTS playback, the wake detector is disabled. This prevents the assistant from hearing its own output and re-triggering.

6. **Barge-in with RMS detection** â€” During TTS sentence gaps, an RMS energy detector checks for real human speech. Consecutive high-energy frames trigger interruption, stopping TTS and resuming STT.

7. **Settings persistence** â€” Wake words and display name are editable in the web UI. Changes are persisted directly to the `.env` file and broadcast to all connected clients via WebSocket.

8. **All services on localhost** â€” Security by default. No external network exposure.

---

## License

See [LICENSE](LICENSE).
